Word2Vec - Easily Explained

=> The main drawback of BOW(Bag of Words) and TF-IDF is that the semantic information(ie meaning of the word is not considered) and the order in which the words occur in a sentence is not preserved.

=> This might lead to overfitting.

Thus, Word2Vec is used to convert the words to 32 or more dimensional vectors by considering the semantic as well as the order in which the words appear

For example, In a sentence that has the words "man" and "woman" 
Representing in a 2D space, the word "man" can have a vector - (8, 6)
Representing in a 2D space, the word "woman" can have a vector - (8.2, 6.4)
since the word "woman" has the sub-word "man", the two vectors can be interrelated and the difference is minimal. For the word "hello", it might be (10, 14)
