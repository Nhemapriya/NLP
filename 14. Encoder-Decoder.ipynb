{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14. Encoder/Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYtA-wTZNrjw"
      },
      "source": [
        "# Neural Machine Learning Language Translation using encoder-decoder \n",
        "\n",
        "Dataset : French to english translation\n",
        "\n",
        "http://www.manythings.org/anki/\n",
        "\n",
        "Reference : https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dtQoYZyuTfR"
      },
      "source": [
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and corresponding target sequences from another domain\n",
        "    (e.g. French sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    It uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUiBvYiXOMQt"
      },
      "source": [
        "**Initialization and imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24JT1JesNhdI"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, LSTM\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "#dimensions of latent vector\n",
        "latent_dim = 256\n",
        "#total number of samples\n",
        "num_samples = 10000\n",
        "#path to dataset\n",
        "data_path = '/content/drive/MyDrive/NLP/fra.txt'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF0C0w3AO9KA"
      },
      "source": [
        "**vectorize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJgoZ20OOL0-"
      },
      "source": [
        "#english and french words\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "#english and french characters\n",
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5r49utZPBMW"
      },
      "source": [
        "\n",
        "#open file in read mode\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    #add the leftout characters\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIxWA6pNY1fw"
      },
      "source": [
        "**Define the parameters in variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvSHpG1V0V4"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pakGaaeOLx7"
      },
      "source": [
        "#obtain the dictionary tokens and pair\n",
        "\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)]\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp4BWhS0bPn6",
        "outputId": "3bd2573a-44e6-4862-a28c-370869af3e14"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " '%': 4,\n",
              " '&': 5,\n",
              " \"'\": 6,\n",
              " ',': 7,\n",
              " '-': 8,\n",
              " '.': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '5': 14,\n",
              " '7': 15,\n",
              " '8': 16,\n",
              " '9': 17,\n",
              " ':': 18,\n",
              " '?': 19,\n",
              " 'A': 20,\n",
              " 'B': 21,\n",
              " 'C': 22,\n",
              " 'D': 23,\n",
              " 'E': 24,\n",
              " 'F': 25,\n",
              " 'G': 26,\n",
              " 'H': 27,\n",
              " 'I': 28,\n",
              " 'J': 29,\n",
              " 'K': 30,\n",
              " 'L': 31,\n",
              " 'M': 32,\n",
              " 'N': 33,\n",
              " 'O': 34,\n",
              " 'P': 35,\n",
              " 'Q': 36,\n",
              " 'R': 37,\n",
              " 'S': 38,\n",
              " 'T': 39,\n",
              " 'U': 40,\n",
              " 'V': 41,\n",
              " 'W': 42,\n",
              " 'Y': 43,\n",
              " 'a': 44,\n",
              " 'b': 45,\n",
              " 'c': 46,\n",
              " 'd': 47,\n",
              " 'e': 48,\n",
              " 'f': 49,\n",
              " 'g': 50,\n",
              " 'h': 51,\n",
              " 'i': 52,\n",
              " 'j': 53,\n",
              " 'k': 54,\n",
              " 'l': 55,\n",
              " 'm': 56,\n",
              " 'n': 57,\n",
              " 'o': 58,\n",
              " 'p': 59,\n",
              " 'q': 60,\n",
              " 'r': 61,\n",
              " 's': 62,\n",
              " 't': 63,\n",
              " 'u': 64,\n",
              " 'v': 65,\n",
              " 'w': 66,\n",
              " 'x': 67,\n",
              " 'y': 68,\n",
              " 'z': 69,\n",
              " 'Ã©': 70}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLjZTO5a34u"
      },
      "source": [
        "#defining the french data parameters\n",
        "\n",
        "#create a numpy array for encoder i/p and decoder i/p & o/p\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrbzx500r-Op"
      },
      "source": [
        "**one hot representation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3j56E6Mr7NA"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kATVhsPbvz6",
        "outputId": "a9f2323f-8612-499d-cdd0-1074f073ebe1"
      },
      "source": [
        "encoder_input_data[0].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 71)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1wkRb4ju0FC"
      },
      "source": [
        "**Model construction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCap5FT1bwTC"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "\n",
        "from tensorflow import keras\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1D6YDwivHAw"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11jDgSKxvEaZ"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqGWOLAlvK-F",
        "outputId": "19087c48-b8d3-41cc-b3b9-9fda674e2714"
      },
      "source": [
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.3484 - accuracy: 0.8950 - val_loss: 0.4641 - val_accuracy: 0.8647\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.3349 - accuracy: 0.8994 - val_loss: 0.4532 - val_accuracy: 0.8674\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.3220 - accuracy: 0.9030 - val_loss: 0.4533 - val_accuracy: 0.8673\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.3100 - accuracy: 0.9065 - val_loss: 0.4507 - val_accuracy: 0.8680\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.2985 - accuracy: 0.9099 - val_loss: 0.4515 - val_accuracy: 0.8688\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2879 - accuracy: 0.9133 - val_loss: 0.4435 - val_accuracy: 0.8716\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.2776 - accuracy: 0.9165 - val_loss: 0.4420 - val_accuracy: 0.8733\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.2680 - accuracy: 0.9188 - val_loss: 0.4422 - val_accuracy: 0.8742\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.2581 - accuracy: 0.9221 - val_loss: 0.4437 - val_accuracy: 0.8742\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.2496 - accuracy: 0.9245 - val_loss: 0.4390 - val_accuracy: 0.8758\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2409 - accuracy: 0.9274 - val_loss: 0.4470 - val_accuracy: 0.8746\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2327 - accuracy: 0.9295 - val_loss: 0.4473 - val_accuracy: 0.8746\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2253 - accuracy: 0.9319 - val_loss: 0.4513 - val_accuracy: 0.8745\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.2173 - accuracy: 0.9342 - val_loss: 0.4505 - val_accuracy: 0.8755\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.2106 - accuracy: 0.9360 - val_loss: 0.4539 - val_accuracy: 0.8756\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2039 - accuracy: 0.9384 - val_loss: 0.4573 - val_accuracy: 0.8754\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1971 - accuracy: 0.9402 - val_loss: 0.4578 - val_accuracy: 0.8759\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.1909 - accuracy: 0.9419 - val_loss: 0.4690 - val_accuracy: 0.8750\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.1849 - accuracy: 0.9436 - val_loss: 0.4701 - val_accuracy: 0.8749\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1790 - accuracy: 0.9454 - val_loss: 0.4756 - val_accuracy: 0.8741\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1742 - accuracy: 0.9469 - val_loss: 0.4773 - val_accuracy: 0.8753\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.1689 - accuracy: 0.9482 - val_loss: 0.4795 - val_accuracy: 0.8748\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1635 - accuracy: 0.9496 - val_loss: 0.4875 - val_accuracy: 0.8747\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.1589 - accuracy: 0.9513 - val_loss: 0.4888 - val_accuracy: 0.8755\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.1541 - accuracy: 0.9527 - val_loss: 0.4970 - val_accuracy: 0.8738\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.1497 - accuracy: 0.9542 - val_loss: 0.5039 - val_accuracy: 0.8739\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1453 - accuracy: 0.9555 - val_loss: 0.5153 - val_accuracy: 0.8730\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.1416 - accuracy: 0.9564 - val_loss: 0.5156 - val_accuracy: 0.8732\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.1376 - accuracy: 0.9574 - val_loss: 0.5181 - val_accuracy: 0.8738\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1342 - accuracy: 0.9585 - val_loss: 0.5215 - val_accuracy: 0.8738\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.1301 - accuracy: 0.9598 - val_loss: 0.5293 - val_accuracy: 0.8738\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1267 - accuracy: 0.9607 - val_loss: 0.5306 - val_accuracy: 0.8735\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.1236 - accuracy: 0.9618 - val_loss: 0.5403 - val_accuracy: 0.8728\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.1204 - accuracy: 0.9626 - val_loss: 0.5429 - val_accuracy: 0.8742\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1172 - accuracy: 0.9635 - val_loss: 0.5511 - val_accuracy: 0.8727\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.1143 - accuracy: 0.9644 - val_loss: 0.5517 - val_accuracy: 0.8734\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.1116 - accuracy: 0.9652 - val_loss: 0.5578 - val_accuracy: 0.8728\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1087 - accuracy: 0.9661 - val_loss: 0.5657 - val_accuracy: 0.8727\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1064 - accuracy: 0.9667 - val_loss: 0.5676 - val_accuracy: 0.8730\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.1039 - accuracy: 0.9671 - val_loss: 0.5688 - val_accuracy: 0.8729\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 49s 393ms/step - loss: 0.1010 - accuracy: 0.9683 - val_loss: 0.5782 - val_accuracy: 0.8735\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.5813 - val_accuracy: 0.8731\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0968 - accuracy: 0.9694 - val_loss: 0.5874 - val_accuracy: 0.8724\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0947 - accuracy: 0.9700 - val_loss: 0.5913 - val_accuracy: 0.8724\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0925 - accuracy: 0.9707 - val_loss: 0.5973 - val_accuracy: 0.8727\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0904 - accuracy: 0.9712 - val_loss: 0.6042 - val_accuracy: 0.8733\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0885 - accuracy: 0.9718 - val_loss: 0.6016 - val_accuracy: 0.8735\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0866 - accuracy: 0.9724 - val_loss: 0.6119 - val_accuracy: 0.8730\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 0.6173 - val_accuracy: 0.8732\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0830 - accuracy: 0.9734 - val_loss: 0.6196 - val_accuracy: 0.8726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f96d148a350>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_A10O3D4mcT",
        "outputId": "6bfd8a66-ab90-44d9-973d-bd42b3ba7b4c"
      },
      "source": [
        "# Save model\n",
        "model.save(\"s2s\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f96d0990e90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f96d0f9ed10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx7tTfcB46Q2"
      },
      "source": [
        "**check the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWpkOYBY4oK6"
      },
      "source": [
        "\"\"\"\n",
        "## Run inference (sampling)\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n",
        "\"\"\"\n",
        "\n",
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri5qsEmi4y2p"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdjosGCt4tqP"
      },
      "source": [
        "**sentence generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQP89r8C4s05",
        "outputId": "77e81b2c-1949-4bf0-d892-3182e32e3001"
      },
      "source": [
        "for seq_index in range(5):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va !\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va !\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L86DakQqzz2f"
      },
      "source": [
        "# Problems with encoder and decoder\n",
        "\n",
        "\n",
        "\n",
        "1.   We know that the ouput of the encoder is the context vector and that is given as input to the decoder. The encoder/decoder architecture does not work well for **longer sentences**\n",
        "2.   In case of longer sentences, the actual information regarding the sentences are not captured completely by the encoder and thus, when given as a input to the decoder, it does not reproduce the outputs effectively.\n",
        "3.   It is observed that if the sentence increases in length , the accuracy decreases.\n",
        "4.   To overcome this problem, **attention models are used** where bidirectional LSTMs are used in encoders to capture all information\n",
        "5.   Attention models make use of window size . (ie) when a paragraph of 1000 words is given , at an instant a window of 10 words is considered and trained incrementally\n"
      ]
    }
  ]
}